<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
</head>
<body>
    <!-- input para el identificador del objeto a entrenar -->
    <input type="text" id="cajaentrenamiento">
    <!-- botón para capturar los datos actuales y almacenarlos en memoria -->
    <button id="procesa">Procesar y guardar</button><br>
    <!-- elemento de video que mostrará el feed en vivo de la cámara web -->
    <video id="webcam" autoplay></video>
    <!-- tres lienzos donde se procesará y mostrará la imagen capturada -->
    <canvas id="canvas"></canvas>
    <canvas id="canvas2"></canvas>
    <canvas id="canvas3"></canvas>
    <!-- texto para mostrar el resultado del reconocimiento -->
    <h1>Esto es un(a) <span id="resultado"></span></h1>
    <script>
        var memoria = []; // array donde se almacenará la memoria de objetos aprendidos
        var neuronas = []; // array para almacenar patrones detectados en cada frame
        const video = document.getElementById('webcam'); // selecciona el elemento de video
        const canvas = document.getElementById('canvas'); // selecciona el primer lienzo
        const contexto = canvas.getContext('2d'); // obtiene el contexto de dibujo para el lienzo

        const canvas2 = document.getElementById('canvas2'); // selecciona el segundo lienzo
        const contexto2 = canvas2.getContext('2d'); // obtiene el contexto del segundo lienzo

        const canvas3 = document.getElementById('canvas3'); // selecciona el tercer lienzo
        const contexto3 = canvas3.getContext('2d'); // obtiene el contexto del tercer lienzo

        // solicita acceso a la cámara del usuario
        navigator.mediaDevices.getUserMedia({ video: true })
            .then((stream) => { // si el acceso es permitido
                video.srcObject = stream; // conecta el feed de la cámara al elemento de video
                video.addEventListener('loadedmetadata', () => { // cuando se carguen los metadatos del video
                    // ajusta el tamaño de los lienzos al tamaño del video
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    canvas2.width = video.videoWidth;
                    canvas2.height = video.videoHeight;
                    canvas3.width = video.videoWidth;
                    canvas3.height = video.videoHeight;

                    // función para procesar y dibujar el contenido
                    function draw() {
                        // copia el feed de la cámara al primer lienzo
                        contexto.drawImage(video, 0, 0, canvas.width, canvas.height);

                        // obtiene los datos de la imagen del primer lienzo
                        var datos = contexto.getImageData(0, 0, canvas.width, canvas.height);

                        // establece un umbral para detectar bordes
                        let umbral = 25;

                        // recorre todos los píxeles del lienzo
                        for (let i = 0; i < datos.data.length; i += 4) {
                            // detecta cambios significativos entre píxeles vecinos (bordes)
                            if (
                                Math.abs(datos.data[i] - datos.data[i + 4]) > umbral || // diferencia horizontal
                                Math.abs(datos.data[i] - datos.data[i + canvas.width * 4]) > umbral // diferencia vertical
                            ) {
                                // si es un borde, lo pinta de negro
                                datos.data[i] = 0;
                                datos.data[i + 1] = 0;
                                datos.data[i + 2] = 0;
                            } else {
                                // si no es un borde, lo pinta de blanco
                                datos.data[i] = 255;
                                datos.data[i + 1] = 255;
                                datos.data[i + 2] = 255;
                            }
                        }

                        // dibuja la imagen procesada en el segundo lienzo
                        contexto2.putImageData(datos, 0, 0);

                        // resetea el array de patrones
                        neuronas = [];

                        // recorre la imagen procesada en bloques de 2x2
                        for (let x = 0; x < video.videoWidth; x += 2) {
                            for (let y = 0; y < video.videoHeight; y += 2) {
                                // obtiene un bloque de 2x2 píxeles
                                let bloque = contexto2.getImageData(x, y, 2, 2);

                                // convierte los valores de los píxeles en una cadena binaria
                                let cadena = "";
                                for (let i = 0; i < bloque.data.length; i += 4) {
                                    cadena += bloque.data[i] === 255 ? "1" : "0";
                                }

                                // registra el patrón en el array de neuronas
                                if (neuronas[cadena] == undefined) {
                                    neuronas[cadena] = 1;
                                } else {
                                    neuronas[cadena]++;
                                }
                            }
                        }

                        // compara los patrones actuales con la memoria
                        for (let i = 0; i < memoria.length; i++) {
                            if (arraysEqual(neuronas, memoria[i].datos)) {
                                // si coincide con un registro en memoria, muestra el identificador
                                document.querySelector("#resultado").textContent = memoria[i].identificador;
                            } else {
                                // si no coincide, limpia el resultado
                                document.querySelector("#resultado").textContent = "";
                            }
                        }

                        // limpia el tercer lienzo
                        contexto3.clearRect(0, 0, video.videoWidth, video.videoHeight);

                        // dibuja una gráfica de barras con los patrones detectados
                        for (let i = 0; i < 16; i++) {
                            let binary = i.toString(2).padStart(4, '0');
                            contexto3.fillRect(0, i * 16, neuronas[binary] || 0, 14);
                        }

                        // solicita volver a dibujar en el siguiente frame
                        requestAnimationFrame(draw);
                    }

                    // inicia el proceso de dibujo
                    draw();
                });
            })
            .catch((err) => { // si hay un error al acceder a la cámara
                console.error('Error accessing the webcam:', err); // muestra el error en la consola
            });

        // función para guardar el estado actual en memoria cuando se presiona el botón
        document.querySelector("button").onclick = function () {
            memoria.push({
                "identificador": document.querySelector("input").value, // obtiene el identificador del objeto
                "datos": neuronas // guarda el patrón detectado
            });
            console.log(memoria); // muestra la memoria en la consola
        };

        // función para comparar dos arrays
        function arraysEqual(arr1, arr2) {
            if (arr1.length !== arr2.length) return false;

            for (let i = 0; i < arr1.length; i++) {
                if (arr1[i] !== arr2[i]) return false;
            }

            return true;
        }
    </script>
</body>
</html>
